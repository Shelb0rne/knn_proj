# knn_proj
Визуализация решающих поверхностей в kNN. Написание кода алгоритма KNN

# KNN Penguin Classification

## Описание проекта

Данный проект реализует задачу классификации видов пингвинов с помощью алгоритма *k-ближайших соседей (K-Nearest Neighbors)* на основе открытого датасета `penguins_data.csv`. В проекте представлены:

* Предобработка данных (очистка, кодирование категориальных признаков, стандартизация);
* Обучение KNN-моделей с использованием библиотеки `scikit-learn`;
* Визуализация границ принятия решений;
* Реализация собственного класса KNN с нуля на NumPy;
* Сравнение точности моделей на тестовой выборке при различных значениях параметра `k`.

## Используемые признаки

Для обучения моделей выбраны два признака:

* Длина плавника (Flipper Length, мм);
* Масса тела (Body Mass, г).

Эти признаки позволяют наиболее наглядно визуализировать границы принятия решений и хорошо разделяют целевые классы.

## Результаты

Модель `KNN` была обучена с различными значениями `k` (1, 3, 5, 10, 15, 25). Были получены следующие точности на тестовой выборке:

| K  | Accuracy |
| -- | -------- |
| 1  | 0.93     |
| 3  | 0.92     |
| 5  | 0.91     |
| 10 | 0.90     |
| 15 | 0.88     |
| 25 | 0.86     |

Наилучшая точность наблюдается при `k = 1`. Это объясняется тем, что при малом `k` модель максимально чувствительна к локальной структуре данных, что при малом шуме и явных кластерах может давать высокую точность.

Также была реализована своя версия алгоритма KNN без использования `scikit-learn`, которая показала сопоставимые результаты.

## Визуализация

Границы принятия решений для разных значений `k` были построены с помощью `mlxtend.plotting.plot_decision_regions`. Они демонстрируют, как увеличение `k` сглаживает границы и снижает риск переобучения, но может привести к потере чувствительности к структуре данных.
![image](https://github.com/user-attachments/assets/12ddddb8-4d1f-4dbc-9f44-42fc4f666404)


## Выводы и интерпретация

* Алгоритм KNN хорошо подходит для задачи классификации пингвинов по физиологическим признакам.
* При низких значениях `k` (1–3) наблюдается высокая точность, но возможен риск переобучения.
* При высоких значениях `k` (10–25) модель становится более устойчивой, но теряет локальную чувствительность.
* Собственная реализация KNN подтверждает логику работы алгоритма и совпадает по качеству с библиотечной версией.

## Автор
Цуркан Игорь

